{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Data Fetching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, types\n",
    "from pyspark.sql.functions import col, year, month, mean, median, udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/30 21:13:05 WARN Utils: Your hostname, Alvees-MBP.local resolves to a loopback address: 127.0.0.1; using 192.168.1.155 instead (on interface en0)\n",
      "23/10/30 21:13:05 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Ivy Default Cache set to: /Users/alvee/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/alvee/.ivy2/jars\n",
      "org.apache.hadoop#hadoop-azure added as a dependency\n",
      "com.microsoft.azure#azure-storage added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-7d5c9ebb-09b8-4b1b-ad58-6990075f84d5;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.hadoop#hadoop-azure;3.3.1 in central\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/Users/alvee/anaconda3/envs/nyc_taxi_ride_alvee/lib/python3.11/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tfound org.apache.httpcomponents#httpclient;4.5.13 in local-m2-cache\n",
      "\tfound org.apache.httpcomponents#httpcore;4.4.13 in local-m2-cache\n",
      "\tfound commons-logging#commons-logging;1.1.3 in central\n",
      "\tfound commons-codec#commons-codec;1.11 in local-m2-cache\n",
      "\tfound org.apache.hadoop.thirdparty#hadoop-shaded-guava;1.1.1 in central\n",
      "\tfound org.eclipse.jetty#jetty-util-ajax;9.4.40.v20210413 in central\n",
      "\tfound org.eclipse.jetty#jetty-util;9.4.40.v20210413 in central\n",
      "\tfound org.codehaus.jackson#jackson-mapper-asl;1.9.13 in central\n",
      "\tfound org.codehaus.jackson#jackson-core-asl;1.9.13 in central\n",
      "\tfound org.wildfly.openssl#wildfly-openssl;1.0.7.Final in central\n",
      "\tfound com.microsoft.azure#azure-storage;8.6.6 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-core;2.9.4 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.12 in central\n",
      "\tfound org.apache.commons#commons-lang3;3.4 in central\n",
      "\tfound com.microsoft.azure#azure-keyvault-core;1.2.4 in central\n",
      "\tfound com.google.guava#guava;24.1.1-jre in central\n",
      "\tfound com.google.code.findbugs#jsr305;1.3.9 in local-m2-cache\n",
      "\tfound org.checkerframework#checker-compat-qual;2.0.0 in local-m2-cache\n",
      "\tfound com.google.errorprone#error_prone_annotations;2.1.3 in local-m2-cache\n",
      "\tfound com.google.j2objc#j2objc-annotations;1.1 in local-m2-cache\n",
      "\tfound org.codehaus.mojo#animal-sniffer-annotations;1.14 in local-m2-cache\n",
      ":: resolution report :: resolve 243ms :: artifacts dl 12ms\n",
      "\t:: modules in use:\n",
      "\tcom.fasterxml.jackson.core#jackson-core;2.9.4 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;1.3.9 from local-m2-cache in [default]\n",
      "\tcom.google.errorprone#error_prone_annotations;2.1.3 from local-m2-cache in [default]\n",
      "\tcom.google.guava#guava;24.1.1-jre from central in [default]\n",
      "\tcom.google.j2objc#j2objc-annotations;1.1 from local-m2-cache in [default]\n",
      "\tcom.microsoft.azure#azure-keyvault-core;1.2.4 from central in [default]\n",
      "\tcom.microsoft.azure#azure-storage;8.6.6 from central in [default]\n",
      "\tcommons-codec#commons-codec;1.11 from local-m2-cache in [default]\n",
      "\tcommons-logging#commons-logging;1.1.3 from central in [default]\n",
      "\torg.apache.commons#commons-lang3;3.4 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-azure;3.3.1 from central in [default]\n",
      "\torg.apache.hadoop.thirdparty#hadoop-shaded-guava;1.1.1 from central in [default]\n",
      "\torg.apache.httpcomponents#httpclient;4.5.13 from local-m2-cache in [default]\n",
      "\torg.apache.httpcomponents#httpcore;4.4.13 from local-m2-cache in [default]\n",
      "\torg.checkerframework#checker-compat-qual;2.0.0 from local-m2-cache in [default]\n",
      "\torg.codehaus.jackson#jackson-core-asl;1.9.13 from central in [default]\n",
      "\torg.codehaus.jackson#jackson-mapper-asl;1.9.13 from central in [default]\n",
      "\torg.codehaus.mojo#animal-sniffer-annotations;1.14 from local-m2-cache in [default]\n",
      "\torg.eclipse.jetty#jetty-util;9.4.40.v20210413 from central in [default]\n",
      "\torg.eclipse.jetty#jetty-util-ajax;9.4.40.v20210413 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.12 from central in [default]\n",
      "\torg.wildfly.openssl#wildfly-openssl;1.0.7.Final from central in [default]\n",
      "\t:: evicted modules:\n",
      "\tcom.microsoft.azure#azure-storage;7.0.1 by [com.microsoft.azure#azure-storage;8.6.6] in [default]\n",
      "\torg.apache.commons#commons-lang3;3.8.1 by [org.apache.commons#commons-lang3;3.4] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   24  |   0   |   0   |   2   ||   22  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-7d5c9ebb-09b8-4b1b-ad58-6990075f84d5\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 22 already retrieved (0kB/6ms)\n",
      "23/10/30 21:13:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "          .master(\"local[*]\") \\\n",
    "          .appName(\"TaxiDataProcessing\") \\\n",
    "          .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-azure:3.3.1,com.microsoft.azure:azure-storage:8.6.6\") \\\n",
    "          .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remote blob path: wasbs://nyctlc@azureopendatastorage.blob.core.windows.net/yellow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/30 21:13:07 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-azure-file-system.properties,hadoop-metrics2.properties\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Azure storage access info\n",
    "blob_account_name = \"azureopendatastorage\"\n",
    "blob_container_name = \"nyctlc\"\n",
    "blob_relative_path = \"yellow\"\n",
    "blob_sas_token = \"r\"\n",
    "\n",
    "# Allow Spark to read from Blob remotely\n",
    "wasbs_path = 'wasbs://%s@%s.blob.core.windows.net/%s' % (blob_container_name, blob_account_name, blob_relative_path)\n",
    "spark.conf.set(\n",
    "  'fs.azure.sas.%s.%s.blob.core.windows.net' % (blob_container_name, blob_account_name),\n",
    "  blob_sas_token)\n",
    "  \n",
    "print('Remote blob path: ' + wasbs_path)\n",
    "\n",
    "df = spark.read.parquet(wasbs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- vendorID: string (nullable = true)\n",
      " |-- tpepPickupDateTime: timestamp (nullable = true)\n",
      " |-- tpepDropoffDateTime: timestamp (nullable = true)\n",
      " |-- passengerCount: integer (nullable = true)\n",
      " |-- tripDistance: double (nullable = true)\n",
      " |-- puLocationId: string (nullable = true)\n",
      " |-- doLocationId: string (nullable = true)\n",
      " |-- startLon: double (nullable = true)\n",
      " |-- startLat: double (nullable = true)\n",
      " |-- endLon: double (nullable = true)\n",
      " |-- endLat: double (nullable = true)\n",
      " |-- rateCodeId: integer (nullable = true)\n",
      " |-- storeAndFwdFlag: string (nullable = true)\n",
      " |-- paymentType: string (nullable = true)\n",
      " |-- fareAmount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mtaTax: double (nullable = true)\n",
      " |-- improvementSurcharge: string (nullable = true)\n",
      " |-- tipAmount: double (nullable = true)\n",
      " |-- tollsAmount: double (nullable = true)\n",
      " |-- totalAmount: double (nullable = true)\n",
      " |-- puYear: integer (nullable = true)\n",
      " |-- puMonth: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@udf(types.StringType())\n",
    "def get_payment_type(payment_type: str):\n",
    "    payment_type_map = {\n",
    "        '1': 'Credit card',\n",
    "        '2': 'Cash',\n",
    "        '3': 'No charge',\n",
    "        '4': 'Dispute',\n",
    "        '5': 'Unknown',\n",
    "        '6': 'Voided trip',\n",
    "    }\n",
    "    \n",
    "    return payment_type_map.get(payment_type.strip(), None)\n",
    "\n",
    "df = df.withColumn('paymentType', get_payment_type(df.paymentType))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.filter((col(\"passengerCount\") > 0) \n",
    "                & (col(\"paymentType\").isNotNull())\n",
    "                & (col(\"puYear\") >= 2009) \n",
    "                & (col(\"puYear\") <= 2018))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg = df.groupBy(\n",
    "        col(\"paymentType\"), \n",
    "        col(\"puYear\").alias(\"year\"), \n",
    "        col(\"puMonth\").alias(\"month\")\n",
    "      ).agg(\n",
    "        mean(\"fareAmount\").alias(\"meanFareAmount\"),\n",
    "        median(\"fareAmount\").alias(\"medianFareAmount\"),\n",
    "        mean(\"totalAmount\").alias(\"meanTotalAmount\"),\n",
    "        median(\"totalAmount\").alias(\"medianTotalAmount\"),\n",
    "        mean(\"passengerCount\").alias(\"meanPassengerCount\"),\n",
    "        median(\"passengerCount\").alias(\"medianPassengerCount\")\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate data using Spark SQL query\n",
    "\n",
    "# df.createOrReplaceTempView(\"taxi_data\")\n",
    "\n",
    "# sql_query = \"\"\"\n",
    "# SELECT\n",
    "#     paymentType,\n",
    "#     puYear AS year,\n",
    "#     puMonth AS month,\n",
    "#     AVG(fareAmount) AS meanFareAmount,\n",
    "#     PERCENTILE(fareAmount, 0.5) AS medianFareAmount,\n",
    "#     AVG(totalAmount) AS meanTotalAmount,\n",
    "#     PERCENTILE(totalAmount, 0.5) AS medianTotalAmount,\n",
    "#     AVG(passengerCount) AS meanPassengerCount,\n",
    "#     PERCENTILE(passengerCount, 0.5) AS medianPassengerCount\n",
    "# FROM taxi_data\n",
    "# WHERE passengerCount > 0 AND paymentType IS NOT NULL\n",
    "# GROUP BY paymentType, year, month\n",
    "# \"\"\"\n",
    "\n",
    "# df_agg = spark.sql(sql_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/30 21:21:21 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "23/10/30 21:21:21 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 84.44% for 9 writers\n",
      "23/10/30 21:21:21 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 76.00% for 10 writers\n",
      "23/10/30 21:21:21 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 84.44% for 9 writers\n",
      "23/10/30 21:21:21 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "output_path = \"./data/result_explore/\"\n",
    "df_agg.write.partitionBy(\"paymentType\", \"year\", \"month\").parquet(output_path, mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Local Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- meanFareAmount: double (nullable = true)\n",
      " |-- medianFareAmount: double (nullable = true)\n",
      " |-- meanTotalAmount: double (nullable = true)\n",
      " |-- medianTotalAmount: double (nullable = true)\n",
      " |-- meanPassengerCount: double (nullable = true)\n",
      " |-- medianPassengerCount: double (nullable = true)\n",
      " |-- paymentType: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_local = spark.read.parquet(\"./data/result_explore\")\n",
    "df_local.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----------------+------------------+-----------------+------------------+--------------------+-----------+----+-----+\n",
      "|    meanFareAmount|medianFareAmount|   meanTotalAmount|medianTotalAmount|meanPassengerCount|medianPassengerCount|paymentType|year|month|\n",
      "+------------------+----------------+------------------+-----------------+------------------+--------------------+-----------+----+-----+\n",
      "|10.949047720642925|             8.0|12.216734030414708|              9.3|1.7140974414180248|                 1.0|       Cash|2015|    1|\n",
      "|11.261226190383946|             8.0|12.564796420455288|              9.3| 1.648360535101513|                 1.0|       Cash|2018|    1|\n",
      "|13.282471413045489|            10.0| 17.42523316947812|            12.96| 1.656186660678024|                 1.0|Credit card|2015|    3|\n",
      "|12.998312242744888|             9.5|17.112745963811772|             12.6| 1.656975895647892|                 1.0|Credit card|2016|    1|\n",
      "|11.815727206707598|             8.0|13.200907770515643|              9.3|   1.3156400607381|                 1.0|    Dispute|2016|   12|\n",
      "|10.823785852542668|             7.5|12.062152912194017|              8.3| 1.315150448706669|                 1.0|    Dispute|2018|    2|\n",
      "|10.580707891246684|             7.5| 11.70327088859424|              8.8| 1.365716180371353|                 1.0|    Dispute|2018|    8|\n",
      "|10.226931764334227|             7.5|11.418098246722462|              8.3|1.3402306112778393|                 1.0|    Dispute|2018|   10|\n",
      "|              52.5|            52.5|              64.8|             64.8|               2.0|                 2.0|    Unknown|2016|    9|\n",
      "|               4.5|             4.5|               5.3|              5.3|               1.0|                 1.0|    Unknown|2018|   11|\n",
      "+------------------+----------------+------------------+-----------------+------------------+--------------------+-----------+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_local.limit(10).orderBy('paymentType', 'year', 'month').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nyc_taxi_ride_alvee",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
